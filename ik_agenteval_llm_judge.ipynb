{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinesh-245/AI-evaluation/blob/main/ik_agenteval_llm_judge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Evaluation Homework for non-SWE\n",
        "\n",
        "This module demonstrates using LangSmith to monitor your agent in production. You need to have created a langsmith account, and have your custom openAI keys.\n"
      ],
      "metadata": {
        "id": "g8MaN8vLNULd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
        "\n",
        "Note that observability is important throughout all stages of application development - from prototyping, to beta testing, to production. There are different considerations at all stages, but they are all intricately tied together. In this tutorial we walk through the natural progression.\n",
        "\n",
        "Let's assume that we're building a simple RAG application using the OpenAI SDK. The simple application we're adding observability to looks like."
      ],
      "metadata": {
        "id": "CP6THF7ptowd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to homework document: https://docs.google.com/document/d/1IrgnVLXtHcx0TJ0IJlUzrHsqseM23eGh7DdpYEkzJvU/edit?tab=t.0\n"
      ],
      "metadata": {
        "id": "0C_SXreFIZlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install langsmith\n",
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "from langsmith import traceable\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
        "#os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "#os.environ[\"LANGSMITH_API_KEY\"] =  userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<enter-your-own-key-here>\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"<enter-your-own-key-here>\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8NREszw7el",
        "outputId": "843b3c3d-18ab-44d1-9c8a-1df822b10452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1 - Running the first Basic App**\n",
        "\n",
        "Let's first build a basic LLM application, with a basic calls wrapped around LangSmith. Run the below, and check out what is showing up on the LangSmith Portal."
      ],
      "metadata": {
        "id": "vIAFEc5qGNU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = wrap_openai(OpenAI())\n",
        "\n",
        "def retriever(query: str):\n",
        "    results = [\"Harrison worked at Kensho\"]\n",
        "    return results\n",
        "\n",
        "def rag(question):\n",
        "    docs = retriever(question)\n",
        "    system_message = \"\"\"Answer the users question using only the provided information below:\n",
        "\n",
        "    {docs}\"\"\".format(docs=\"\\n\".join(docs))\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "3iaqyLrKGDhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2 - Run the LangSmith enhanced version**\n",
        "\n",
        "The first thing you might want to trace is all your OpenAI calls. After all, this is where the LLM is actually being called, so it is the most important part! We've tried to make this as easy as possible with LangSmith by introducing a dead-simple OpenAI wrapper. All you have to do is modify your code to look something like:"
      ],
      "metadata": {
        "id": "jktFnZ1Eufxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we import from langsmith.wrappers import wrap_openai and use it to wrap the OpenAI client (openai_client = wrap_openai(OpenAI())).\n"
      ],
      "metadata": {
        "id": "OOBoFyHjuvZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we import from langsmith import traceable and use it decorate the overall function (@traceable).\n"
      ],
      "metadata": {
        "id": "bC55N2FvxTwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we import from langsmith import traceable and use it decorate the overall function (@traceable(run_type=\"retriever\")).\n",
        "\n",
        "What happens if you call it in the following way?"
      ],
      "metadata": {
        "id": "IaglAo68xmRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beta Testing\n",
        "The next stage of LLM application development is beta testing your application. This is when you release it to a few initial users. Having good observability set up here is crucial as often you don't know exactly how users will actually use your application, so this allows you get insights into how they do so. This also means that you probably want to make some changes to your tracing set up to better allow for that. This extends the observability you set up in the previous section\n",
        "\n",
        "# Collecting Feedback\n",
        "A huge part of having good observability during beta testing is collecting feedback. What feedback you collect is often application specific - but at the very least a simple thumbs up/down is a good start. After logging that feedback, you need to be able to easily associate it with the run that caused that. Luckily LangSmith makes it easy to do that.\n",
        "\n",
        "First, you need to log the feedback from your app. An easy way to do this is to keep track of a run ID for each run, and then use that to log feedback. Keeping track of the run ID would look something like:"
      ],
      "metadata": {
        "id": "AEzsGaWFxxzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging Metadata\n",
        "It is also a good idea to start logging metadata. This allows you to start keep track of different attributes of your app. This is important in allowing you to know what version or variant of your app was used to produce a given result.\n",
        "\n",
        "For this example, we will log the LLM used. Oftentimes you may be experimenting with different LLMs, so having that information as metadata can be useful for filtering. In order to do that, we can add it as such:"
      ],
      "metadata": {
        "id": "KZ6UsJ_eyMvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = wrap_openai(OpenAI())\n",
        "\n",
        "@traceable(run_type=\"retriever\")\n",
        "def retriever(query: str):\n",
        "    results = [\"Harrison worked at Kensho\"]\n",
        "    return results\n",
        "\n",
        "\n",
        "@traceable(metadata={\"llm\": \"gpt-4o-mini\"})\n",
        "def rag(question):\n",
        "    docs = retriever(question)\n",
        "    system_message = \"\"\"Answer the users question using only the provided information below:\n",
        "\n",
        "    {docs}\"\"\".format(docs=\"\\n\".join(docs))\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# Let's do a successful run\n",
        "import uuid\n",
        "\n",
        "run_id = str(uuid.uuid4())\n",
        "rag(\n",
        "    \"where did harrison work\",\n",
        "    langsmith_extra={\"run_id\": run_id, \"metadata\": {\"user_id\": \"harrison\"}}\n",
        ")\n",
        "\n",
        "from langsmith import Client\n",
        "ls_client = Client()\n",
        "ls_client.create_feedback(\n",
        "    run_id,\n",
        "    key=\"user-score\",\n",
        "    score=1.0,\n",
        ")\n",
        "\n",
        "# Let's do a bad  run\n",
        "run_id = str(uuid.uuid4())\n",
        "print(run_id)\n",
        "\n",
        "rag(\n",
        "    \"where did peter work\",\n",
        "    langsmith_extra={\"run_id\": run_id, \"metadata\": {\"user_id\": \"peter\"}}\n",
        ")\n",
        "\n",
        "ls_client.create_feedback(\n",
        "    run_id,\n",
        "    key=\"user-score\",\n",
        "    score=0.0,\n",
        ")"
      ],
      "metadata": {
        "id": "xnGjZ-6Lxg8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observing what happens\n",
        "\n",
        "You have now just run a app with Langsmith integreated with 1)tracing, 2)extra metadata, 3)feedback.\n",
        "\n",
        "After successfully running this, let's goto the LangSmith website to check out\n",
        "1)the traces from Rag to retriever to the OpenAI call\n",
        "2)the metadata that we added on user_id and llm model\n",
        "3)the feedback added for the track.\n",
        "\n",
        "\n",
        "Next, let's try to query by feedback that is positive\n",
        "\n",
        "Next, let's try to query the feedback that is negative.\n",
        "\n",
        "Last, let's look at the monitoring dashboard."
      ],
      "metadata": {
        "id": "VxXmTNaPHTTU"
      }
    }
  ]
}